NAME
    App::UniqFiles - Report or omit duplicate file contents

VERSION
    version 0.03

SYNOPSIS
     # See uniq-files script

DESCRIPTION
FUNCTIONS
    None are exported, but they are exportable.

  uniq_files(%args) -> [STATUS_CODE, ERR_MSG, RESULT]
    Report or omit duplicate file contents.

    Given a list of filenames, will check each file size and content for
    duplicate content. Interface is a bit like the `uniq` Unix command-line
    program.

    Returns a 3-element arrayref. STATUS_CODE is 200 on success, or an error
    code between 3xx-5xx (just like in HTTP). ERR_MSG is a string containing
    error message, RESULT is the actual result.

    Arguments ("*" denotes required arguments):

    *   files* => *array*

    *   count => *bool* (default 0)

        Whether to return each file content's number of occurence.

        1 means the file content is only encountered once (unique), 2 means
        there is one duplicate, and so on.

    *   report_duplicate => *int* (default 2)

        Whether to return duplicate items.

        Can be set to either 0, 1, 2.

        If set to 2 (the default), will only return the first of duplicate
        items. For example: file1 contains text 'a', file2 'b', file3 'a'.
        Only file1 will be returned because file2 is unique and file3
        contains 'a' (already represented by file1).

        If set to 1, will return all the the duplicate items. From the above
        example: file1 and file3 will be returned.

        If set to 0, duplicate items will not be returned.

    *   report_unique => *bool* (default 1)

        Aliases: d (Alias for --noreport-unique --report-duplicate), u
        (Alias for --report-unique --noreport-duplicate)

        Whether to return unique items.

TODO
    *   Handle symlinks

        Provide options on how to handle symlinks: ignore them? Follow?
        Also, with return_duplicate=2, we should not use the symlink
        (because one of the usage of uniq-files might be to delete duplicate
        files).

    *   Handle special files (socket, pipe, device)

        Ignore them.

    *   Check hardlinks/inodes first

        For fast checking.

    *   Arguments hash_skip_bytes & hash_bytes

        For only checking uniqueness against parts of contents.

    *   Arguments hash_module/hash_method/hash_sub

        For doing custom hashing instead of Digest::MD5.

AUTHOR
    Steven Haryanto <stevenharyanto@gmail.com>

COPYRIGHT AND LICENSE
    This software is copyright (c) 2011 by Steven Haryanto.

    This is free software; you can redistribute it and/or modify it under
    the same terms as the Perl 5 programming language system itself.

